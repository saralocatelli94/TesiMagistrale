{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wfdb\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.fftpack import fft, ifft\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcola_NN50_v1(rr_list):\n",
    "    NN50_v1_count=0\n",
    "    for i in range(0,len(rr_list)-1): \n",
    "        if(abs(rr_list[i]-rr_list[i+1])-0.050>=0):\n",
    "            NN50_v1_count+=1\n",
    "    return NN50_v1_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcola_NN50_v2(list):\n",
    "    NN50_v2_count=0\n",
    "    for i in range(1,len(list)):\n",
    "        if(abs(list[i]-list[i-1])-0.050>=0):\n",
    "            NN50_v2_count+=1\n",
    "    return NN50_v2_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serial_corr(y1, lag=1):\n",
    "    y2=np.roll(y1,lag)\n",
    "    m=statistics.mean(y1)\n",
    "    num=0\n",
    "    denom=0\n",
    "#    print(np.corrcoef(y1,y2)[0,1])\n",
    "    for i in range(0,len(y1)):\n",
    "        num+=(y1[i]-m)*(y2[i]-m)\n",
    "        denom+=(y1[i]-m)**2\n",
    "    return num/denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcola_NEP(lista):\n",
    "    sommatoria=0\n",
    "    if(len(lista)<=2):\n",
    "        return(np.nan)\n",
    "    for i in range(1,len(lista)-1):\n",
    "        var=(lista[i]-lista[i-1])*(lista[i+1]-lista[i])\n",
    "        sommatoria+=(1-np.heaviside(var,0.5))\n",
    "    return sommatoria/(len(lista)-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridimensionaDataSet(dfECG,dfAPNEA,dfQRS):\n",
    "    \n",
    "    maxTimeQRS=dfQRS['time'][len(dfQRS)-1]\n",
    "    maxTimeECG=dfECG['time'][len(dfECG)-1]\n",
    "    maxTimeAPN=dfAPNEA['time'][len(dfAPNEA)-1]+60\n",
    "    if(maxTimeAPN<maxTimeECG and maxTimeAPN<maxTimeQRS):\n",
    "        print('a')\n",
    "        dfECG=dfECG[dfECG['time']<=(time_apn[len(time_apn)-1]+60)]\n",
    "        dfQRS=dfQRS[dfQRS['time']<=(time_apn[len(time_apn)-1]+60)]\n",
    "    elif(maxTimeECG<maxTimeAPN and maxTimeECG<maxTimeQRS):\n",
    "        print('b')\n",
    "        dfAPNEA=dfAPNEA[dfAPNEA['time']<=(time_ecg[len(time_ecg)-1])]\n",
    "        dfQRS=dfQRS[dfQRS['time']<=(time_ecg[len(time_ecg)-1])]\n",
    "    elif(maxTimeQRS<maxTimeAPN and maxTimeQRS<maxTimeECG):\n",
    "        print('c')\n",
    "        dfAPNEA=dfAPNEA[dfAPNEA['time']+60<=(time_qrs[len(time_qrs)-1])]\n",
    "        dfECG=dfECG[dfECG['time']<=(time_qrs[len(time_qrs)-1])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creoRRIntervals():\n",
    "    RR_intervals=[]\n",
    "    for i in range (1,len(dfQRS)):\n",
    "        RR_intervals.append(dfQRS['time'][i]-dfQRS['time'][i-1])\n",
    "    RR_intervals.append(np.nan)\n",
    "    dfQRS['rr']=RR_intervals\n",
    "    \n",
    "    rd_intervals=[]\n",
    "    rd_intervals_2=[]\n",
    "    for i in range(0,len(RR_intervals)-1):\n",
    "        rd_intervals.append(RR_intervals[i+1]-RR_intervals[i])\n",
    "    rd_intervals_2=np.power(rd_intervals,2)\n",
    "    return RR_intervals,rd_intervals,rd_intervals_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divisioneIntervalli60():\n",
    "    #divido in epoch di 60 s\n",
    "    lunghezza_intervalli=60*Fs_ecg\n",
    "    df=pd.DataFrame();\n",
    "\n",
    "    startTime=[]\n",
    "    stopTime=[]\n",
    "\n",
    "    startRRIndex=[]\n",
    "    stopRRIndex=[]\n",
    "\n",
    "    numIntervalli=len(dfECG)/lunghezza_intervalli\n",
    "    if(len(ecg)%lunghezza_intervalli!=0):\n",
    "        numIntervalli+=1\n",
    "    print(numIntervalli)\n",
    "    for i in range(0,math.floor(numIntervalli)-1):\n",
    "       # mediaECG.append((ecg[i*lunghezza_intervalli:i*lunghezza_intervalli+lunghezza_intervalli-1]).mean())\n",
    "        startTime.append(dfECG['time'][i*lunghezza_intervalli])\n",
    "        stopTime.append(dfECG['time'][i*lunghezza_intervalli+lunghezza_intervalli-1])\n",
    "       # devECG.append(np.std(ecg[i*lunghezza_intervalli:i*lunghezza_intervalli+lunghezza_intervalli-1]))\n",
    "\n",
    "    df['startTime']=startTime  \n",
    "    df['stopTime']=stopTime  \n",
    "    df['time_apn']=dfAPNEA['time']\n",
    "    df['label']=dfAPNEA['apnea']\n",
    "    #df_10['ECG_mean']=mediaECG  \n",
    "    #df_10['devECG']=devECG  \n",
    "    #return df_10\n",
    "\n",
    "    k=0\n",
    "    for i in range (0, len(df)):\n",
    "            if(k<len(RR_intervals)):\n",
    "                startRRIndex.append(k)\n",
    "                k=k+1\n",
    "                while( k<len(dfQRS) and df['stopTime'][i]>=dfQRS['time'][k] ):\n",
    "                    k=k+1\n",
    "                stopRRIndex.append(k-1)\n",
    "                #print(k-1)\n",
    "           # else:\n",
    "              #  startRRIndex.append(np.nan)\n",
    "               # stopRRIndex.append(np.nan)\n",
    "    df['startRRIndex']=startRRIndex\n",
    "    df['stopRRIndex']=stopRRIndex\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractFeature_RR():\n",
    "    \n",
    "    label=[]\n",
    "    for i in range(0,len(dfAPNEA)):\n",
    "        if(dfAPNEA['apnea'][i]=='N'):\n",
    "            label.append(0)\n",
    "        else:\n",
    "            label.append(1)\n",
    "    df_features=pd.DataFrame()\n",
    "    mediaRR=[]\n",
    "    stdRR=[]\n",
    "    NN50_v1=[]\n",
    "    NN50_v2=[]\n",
    "    pNN50_v1=[]\n",
    "    pNN50_v2=[]\n",
    "    durata=[]\n",
    "    mean_rd=[]\n",
    "    std_rd=[]\n",
    "    RMSDD=[]\n",
    "    serialCC_1=[]\n",
    "    serialCC_2=[]\n",
    "    serialCC_3=[]\n",
    "    serialCC_4=[]\n",
    "    serialCC_5=[]\n",
    "    NEP=[]\n",
    "    for i in range(0,len(df)):\n",
    "        durata.append(df['stopRRIndex'][i]-df['startRRIndex'][i])\n",
    "        mediaRR.append(statistics.mean(RR_intervals[df['startRRIndex'][i]:df['stopRRIndex'][i]]))\n",
    "        stdRR.append(statistics.stdev(RR_intervals[df['startRRIndex'][i]:df['stopRRIndex'][i]]))\n",
    "        NN50_v1.append(calcola_NN50_v1(RR_intervals[df['startRRIndex'][i]:df['stopRRIndex'][i]]))\n",
    "        NN50_v2.append(calcola_NN50_v2(RR_intervals[df['startRRIndex'][i]:df['stopRRIndex'][i]]))\n",
    "        pNN50_v1.append(NN50_v1[i]/durata[i])\n",
    "        pNN50_v2.append(NN50_v2[i]/durata[i])\n",
    "        mean_rd.append(statistics.mean(rd_intervals[df['startRRIndex'][i]:df['stopRRIndex'][i]]))\n",
    "        std_rd.append(statistics.stdev(rd_intervals[df['startRRIndex'][i]:df['stopRRIndex'][i]]))\n",
    "        RMSDD.append(math.sqrt(statistics.mean(rd_intervals_2[df['startRRIndex'][i]:df['stopRRIndex'][i]])))\n",
    "        serialCC_1.append(serial_corr(RR_intervals[df['startRRIndex'][i]:df['stopRRIndex'][i]],1))\n",
    "        serialCC_2.append(serial_corr(RR_intervals[df['startRRIndex'][i]:df['stopRRIndex'][i]],2))\n",
    "        serialCC_3.append(serial_corr(RR_intervals[df['startRRIndex'][i]:df['stopRRIndex'][i]],3))\n",
    "        serialCC_4.append(serial_corr(RR_intervals[df['startRRIndex'][i]:df['stopRRIndex'][i]],4))\n",
    "        serialCC_5.append(serial_corr(RR_intervals[df['startRRIndex'][i]:df['stopRRIndex'][i]],5))\n",
    "        NEP.append(calcola_NEP(RR_intervals[df['startRRIndex'][i]:df['stopRRIndex'][i]]))\n",
    "    df_features['mediaRR']=mediaRR\n",
    "    df_features['stdRR']=stdRR\n",
    "    df_features['NN50_v1']=NN50_v1\n",
    "    df_features['NN50_v2']=NN50_v2\n",
    "    df_features['pNN50_v1']=pNN50_v1\n",
    "    df_features['pNN50_v2']=pNN50_v2\n",
    "    df_features['mean_rd']=mean_rd\n",
    "    df_features['std_rd']=std_rd\n",
    "    df_features['RMSDD']=RMSDD\n",
    "    df_features['serialCC_1']=serialCC_1\n",
    "    df_features['serialCC_2']=serialCC_2\n",
    "    df_features['serialCC_3']=serialCC_3\n",
    "    df_features['serialCC_4']=serialCC_4\n",
    "    df_features['serialCC_5']=serialCC_5\n",
    "    df_features['NEP']=NEP\n",
    "    if(len(label)==len(df_features)+1):\n",
    "        label = label[:-1]\n",
    "    df_features['label']=label\n",
    "    return df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName=['a01','a02','a03','a04','a05','a06','a07','a08','a09','a10','a11','a12','a13','a14','a15','a16','a17','a18','a19','a20',\n",
    "         'b01','b02','b03','b04','b05','c01','c02','c03','c04','c05','c06','c07','c08','c09','c10',\n",
    "         'x01','x02','x03','x04','x05','x06','x07','x08','x09','x10','x11','x12','x13','x14','x15','x16','x17','x18','x19','x20']\n",
    "mypath='C:/Users/sara/Documents/5anno/TESI/DataBase_PhysioNet/www.physionet.org/physiobank/database/apnea-ecg/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "490.00016666666664\n"
     ]
    }
   ],
   "source": [
    "# Valori ECG\n",
    "df_features_list=[]\n",
    "for index in range(0,1):\n",
    "    recordname=mypath+fileName[index]\n",
    "    print(index)\n",
    "    record = wfdb.rdsamp(recordname)\n",
    "    dfECG=pd.DataFrame()\n",
    "    ecg=record[0]\n",
    "    Fs_ecg=record[1]['fs']\n",
    "    intervallo=len(ecg)/(len(ecg)*Fs_ecg)\n",
    "    time_ecg=[]\n",
    "    for i in range(0,len(ecg)):\n",
    "        time_ecg.append(intervallo*i)\n",
    "    dfECG['time']=time_ecg\n",
    "    dfECG['ecg']=ecg\n",
    "\n",
    "    # valori label APNEA\n",
    "    dfAPNEA=pd.DataFrame()\n",
    "    ann = wfdb.rdann(recordname, extension=\"apn\")\n",
    "    time_apn=ann.sample/100\n",
    "    apn=ann.symbol\n",
    "    \n",
    "    dfAPNEA['time']=time_apn\n",
    "    dfAPNEA['apnea']=apn\n",
    "\n",
    "    # valori QRS\n",
    "    dfQRS=pd.DataFrame()\n",
    "    ann = wfdb.rdann(recordname, extension=\"qrs\")\n",
    "    time_qrs=ann.sample/100\n",
    "    dfQRS['time']=time_qrs\n",
    "\n",
    "    #RIDIMENSIONO I DB\n",
    "\n",
    "    maxTimeQRS=dfQRS['time'][len(dfQRS)-1]\n",
    "    maxTimeECG=dfECG['time'][len(dfECG)-1]\n",
    "    maxTimeAPN=dfAPNEA['time'][len(dfAPNEA)-1]\n",
    "    if(maxTimeAPN<maxTimeECG and maxTimeAPN<maxTimeQRS):\n",
    "        dfECG=dfECG[dfECG['time']<=(time_apn[len(time_apn)-1]+60)]\n",
    "        dfQRS=dfQRS[dfQRS['time']<=(time_apn[len(time_apn)-1]+60)]\n",
    "    elif(maxTimeECG<maxTimeAPN and maxTimeECG<maxTimeQRS):\n",
    "        dfAPNEA=dfAPNEA[dfAPNEA['time']<=(time_ecg[len(time_ecg)-1])]\n",
    "        dfQRS=dfQRS[dfQRS['time']<=(time_ecg[len(time_ecg)-1])]\n",
    "    elif(maxTimeQRS<maxTimeAPN and maxTimeQRS<maxTimeECG):\n",
    "        dfAPNEA=dfAPNEA[dfAPNEA['time']+60<=(time_qrs[len(time_qrs)-1])]\n",
    "        dfECG=dfECG[dfECG['time']<=(time_qrs[len(time_qrs)-1])]\n",
    "\n",
    "    #creo RR_intervals\n",
    "    RR_intervals=[]\n",
    "    for i in range (1,len(dfQRS)):\n",
    "        RR_intervals.append(dfQRS['time'][i]-dfQRS['time'][i-1])\n",
    "    RR_intervals.append(np.nan)\n",
    "    dfQRS['rr']=RR_intervals\n",
    "\n",
    "    #CREO EDR con metodo della varianza\n",
    "    \n",
    "\n",
    "    #divido in epoch di 60 s\n",
    "    lunghezza_intervalli=60*Fs_ecg\n",
    "    df=pd.DataFrame();\n",
    "    startTime=[]\n",
    "    stopTime=[]\n",
    "    startRRIndex=[]\n",
    "    stopRRIndex=[]\n",
    "\n",
    "    numIntervalli=len(dfECG)/lunghezza_intervalli\n",
    "    if(len(ecg)%lunghezza_intervalli!=0):\n",
    "        numIntervalli+=1\n",
    "    print(numIntervalli)\n",
    "    for i in range(0,math.floor(numIntervalli)-1):\n",
    "       # mediaECG.append((ecg[i*lunghezza_intervalli:i*lunghezza_intervalli+lunghezza_intervalli-1]).mean())\n",
    "        startTime.append(dfECG['time'][i*lunghezza_intervalli])\n",
    "        stopTime.append(dfECG['time'][i*lunghezza_intervalli+lunghezza_intervalli-1])\n",
    "       # devECG.append(np.std(ecg[i*lunghezza_intervalli:i*lunghezza_intervalli+lunghezza_intervalli-1]))\n",
    "\n",
    "    df['startTime']=startTime  \n",
    "    df['stopTime']=stopTime  \n",
    "    df['time_apn']=dfAPNEA['time']\n",
    "    df['label']=dfAPNEA['apnea']\n",
    "    #df_10['ECG_mean']=mediaECG  \n",
    "    #df_10['devECG']=devECG  \n",
    "    #return df_10\n",
    "\n",
    "    k=0\n",
    "    for i in range (0, len(df)):\n",
    "            if(k<len(RR_intervals)):\n",
    "                startRRIndex.append(k)\n",
    "                k=k+1\n",
    "                while( k<len(dfQRS) and df['stopTime'][i]>=dfQRS['time'][k] ):\n",
    "                    k=k+1\n",
    "                stopRRIndex.append(k-1)\n",
    "                #print(k-1)\n",
    "           # else:\n",
    "              #  startRRIndex.append(np.nan)\n",
    "               # stopRRIndex.append(np.nan)\n",
    "    df['startRRIndex']=startRRIndex\n",
    "    df['stopRRIndex']=stopRRIndex\n",
    "\n",
    "\n",
    "\n",
    "    # calcolo interbeat differentials rd[i]=rr[i+1]−rr[i]\n",
    "    rd_intervals=[]\n",
    "    rd_intervals_2=[]\n",
    "    for i in range(0,len(RR_intervals)-1):\n",
    "        rd_intervals.append(RR_intervals[i+1]-RR_intervals[i])\n",
    "    rd_intervals_2=np.power(rd_intervals,2)\n",
    "\n",
    "    #label\n",
    "    label=[]\n",
    "    for i in range(0,len(dfAPNEA)):\n",
    "        if(dfAPNEA['apnea'][i]=='N'):\n",
    "            label.append(0)\n",
    "        else:\n",
    "            label.append(1)\n",
    "\n",
    "\n",
    "    #CALCOLO LE FEATURES\n",
    "    df_features=pd.DataFrame()\n",
    "    mediaRR=[]\n",
    "    stdRR=[]\n",
    "    NN50_v1=[]\n",
    "    NN50_v2=[]\n",
    "    pNN50_v1=[]\n",
    "    pNN50_v2=[]\n",
    "    durata=[]\n",
    "    mean_rd=[]\n",
    "    std_rd=[]\n",
    "    RMSDD=[]\n",
    "    serialCC_1=[]\n",
    "    serialCC_2=[]\n",
    "    serialCC_3=[]\n",
    "    serialCC_4=[]\n",
    "    serialCC_5=[]\n",
    "    NEP=[]\n",
    "    iqr=[]\n",
    "    db=[]\n",
    "    ffts=[]\n",
    "    for i in range(0,len(df)):\n",
    "        durata.append(df['stopRRIndex'][i]-df['startRRIndex'][i])\n",
    "        if(durata[i]<2):\n",
    "            mediaRR.append(np.nan)\n",
    "            stdRR.append(np.nan)\n",
    "            NN50_v1.append(np.nan)\n",
    "            NN50_v2.append(np.nan)\n",
    "            pNN50_v1.append(np.nan)\n",
    "            pNN50_v2.append(np.nan)\n",
    "            mean_rd.append(np.nan)\n",
    "            std_rd.append(np.nan)\n",
    "            RMSDD.append(np.nan)\n",
    "            serialCC_1.append(np.nan)\n",
    "            serialCC_2.append(np.nan)\n",
    "            serialCC_3.append(np.nan)\n",
    "            serialCC_4.append(np.nan)\n",
    "            serialCC_5.append(np.nan)\n",
    "            NEP.append(np.nan)\n",
    "            iqr.append(np.nan)\n",
    "            ffts.append(np.nan)\n",
    "        else:\n",
    "            mediaRR.append(statistics.mean(RR_intervals[df['startRRIndex'][i]:df['stopRRIndex'][i]]))\n",
    "            stdRR.append(statistics.stdev(RR_intervals[df['startRRIndex'][i]:df['stopRRIndex'][i]]))\n",
    "            NN50_v1.append(calcola_NN50_v1(RR_intervals[df['startRRIndex'][i]:df['stopRRIndex'][i]]))\n",
    "            NN50_v2.append(calcola_NN50_v2(RR_intervals[df['startRRIndex'][i]:df['stopRRIndex'][i]]))\n",
    "            pNN50_v1.append(NN50_v1[i]/durata[i])\n",
    "            pNN50_v2.append(NN50_v2[i]/durata[i])\n",
    "            mean_rd.append(statistics.mean(rd_intervals[df['startRRIndex'][i]:df['stopRRIndex'][i]]))\n",
    "            std_rd.append(statistics.stdev(rd_intervals[df['startRRIndex'][i]:df['stopRRIndex'][i]]))\n",
    "            RMSDD.append(math.sqrt(statistics.mean(rd_intervals_2[df['startRRIndex'][i]:df['stopRRIndex'][i]])))\n",
    "            serialCC_1.append(serial_corr(RR_intervals[df['startRRIndex'][i]:df['stopRRIndex'][i]],1))\n",
    "            serialCC_2.append(serial_corr(RR_intervals[df['startRRIndex'][i]:df['stopRRIndex'][i]],2))\n",
    "            serialCC_3.append(serial_corr(RR_intervals[df['startRRIndex'][i]:df['stopRRIndex'][i]],3))\n",
    "            serialCC_4.append(serial_corr(RR_intervals[df['startRRIndex'][i]:df['stopRRIndex'][i]],4))\n",
    "            serialCC_5.append(serial_corr(RR_intervals[df['startRRIndex'][i]:df['stopRRIndex'][i]],5))\n",
    "            NEP.append(calcola_NEP(RR_intervals[df['startRRIndex'][i]:df['stopRRIndex'][i]]))\n",
    "            q75, q25 = np.percentile(RR_intervals[df['startRRIndex'][i]:df['stopRRIndex'][i]], [75 ,25])\n",
    "            iqr.append(q75 - q25)\n",
    "            ffts.append(fft(RR_intervals[df['startRRIndex'][i]:df['stopRRIndex'][i]]))\n",
    "        db.append(index)\n",
    "        \n",
    "    df_features['db']=db\n",
    "    df_features['mediaRR']=mediaRR\n",
    "    df_features['stdRR']=stdRR\n",
    "    df_features['NN50_v1']=NN50_v1\n",
    "    df_features['NN50_v2']=NN50_v2\n",
    "    df_features['pNN50_v1']=pNN50_v1\n",
    "    df_features['pNN50_v2']=pNN50_v2\n",
    "    df_features['mean_rd']=mean_rd\n",
    "    df_features['std_rd']=std_rd\n",
    "    df_features['RMSDD']=RMSDD\n",
    "    df_features['serialCC_1']=serialCC_1\n",
    "    df_features['serialCC_2']=serialCC_2\n",
    "    df_features['serialCC_3']=serialCC_3\n",
    "    df_features['serialCC_4']=serialCC_4\n",
    "    df_features['serialCC_5']=serialCC_5\n",
    "    df_features['NEP']=NEP\n",
    "    df_features['fft']=ffts\n",
    "    if(len(label)==len(NEP)+1):\n",
    "        label=label[:-1]\n",
    "    df_features['label']=label\n",
    "\n",
    "    df_features=df_features.dropna() \n",
    "    df_features_list.append(df_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#divido ECG in intervalli con i picchi \n",
    "\n",
    "variance=[]\n",
    "i=0\n",
    "for k in range(0,len(dfQRS)):\n",
    "    interv=[]\n",
    "    while(dfECG['time'][i]<dfQRS['time'][k]):\n",
    "        interv.append(dfECG['ecg'][i])\n",
    "        i=i+1    \n",
    "    variance.append(statistics.variance(interv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot\n",
    "#matplotlib.pyplot.psd(RR_intervals[df['startRRIndex'][120]:df['stopRRIndex'][120]], NFFT=256, Fs=0.5, Fc=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfQRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tot=pd.DataFrame()\n",
    "for i in range(0,len(df_features_list)):\n",
    "    df_tot=df_tot.append(df_features_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tot=df_tot.dropna() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''f, axarr = plt.subplots(2, sharex=True,figsize=(10,8))\n",
    "axarr[0].axis([20,30,-3,3])\n",
    "axarr[0].plot(time_ecg,ecg, marker='o',markersize=2, color=\"gray\")\n",
    "#y=[2 for i in range(0,len(dfQRS))]\n",
    "for i in range(20,50):\n",
    "    axarr[0].plot(time_qrs[i],2,marker='*',color='red')\n",
    "axarr[1].step(time_apn,apn)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Domain Feature RR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tot.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_10_normalized=pd.DataFrame()\n",
    "df_10_normalized['mediaRR']=preprocessing.normalize([np.array(df_tot['mediaRR'])])[0]\n",
    "df_10_normalized['stdRR']=preprocessing.normalize([np.array(df_tot['stdRR'])])[0]\n",
    "df_10_normalized['NN50_v1']=preprocessing.normalize([np.array(df_tot['NN50_v1'])])[0]\n",
    "df_10_normalized['NN50_v2']=preprocessing.normalize([np.array(df_tot['NN50_v2'])])[0]\n",
    "df_10_normalized['pNN50_v1']=preprocessing.normalize([np.array(df_tot['pNN50_v1'])])[0]\n",
    "df_10_normalized['pNN50_v2']=preprocessing.normalize([np.array(df_tot['pNN50_v2'])])[0]\n",
    "df_10_normalized['mean_rd']=preprocessing.normalize([np.array(df_tot['mean_rd'])])[0]\n",
    "df_10_normalized['std_rd']=preprocessing.normalize([np.array(df_tot['std_rd'])])[0]\n",
    "df_10_normalized['RMSDD']=preprocessing.normalize([np.array(df_tot['RMSDD'])])[0]\n",
    "df_10_normalized['serialCC_1']=preprocessing.normalize([np.array(df_tot['serialCC_1'])])[0]\n",
    "df_10_normalized['serialCC_2']=preprocessing.normalize([np.array(df_tot['serialCC_2'])])[0]\n",
    "df_10_normalized['serialCC_3']=preprocessing.normalize([np.array(df_tot['serialCC_3'])])[0]\n",
    "df_10_normalized['serialCC_4']=preprocessing.normalize([np.array(df_tot['serialCC_4'])])[0]\n",
    "df_10_normalized['serialCC_5']=preprocessing.normalize([np.array(df_tot['serialCC_5'])])[0]\n",
    "df_10_normalized['NEP']=preprocessing.normalize([np.array(df_tot['NEP'])])[0]\n",
    "df_10_normalized['label']=np.array(df_tot['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from numpy.random import permutation\n",
    "\n",
    "# Randomly shuffle the index of nba.\n",
    "random_indices = permutation(df_10_normalized.index)\n",
    "# Set a cutoff for how many items we want in the test set (in this case 1/3 of the items)\n",
    "test_cutoff = math.floor(len(df_10_normalized)*0.3)\n",
    "# Generate the test set by taking the first 1/3 of the randomly shuffled indices.\n",
    "test = df_10_normalized.loc[random_indices[1:test_cutoff]]\n",
    "# Generate the train set with YYYYYthe rest of the data.\n",
    "train = df_10_normalized.loc[random_indices[test_cutoff:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_10_normalized.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_columns = ['mediaRR', 'stdRR', 'NN50_v1', 'NN50_v2', 'pNN50_v1', 'pNN50_v2',\n",
    "       'mean_rd', 'std_rd','RMSDD', 'serialCC_1', 'serialCC_2', 'serialCC_3',\n",
    "       'serialCC_4', 'serialCC_5', 'NEP']\n",
    "y_column = ['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "# Create the knn model.\n",
    "# Look at the five closest neighbors.\n",
    "knn = KNeighborsRegressor(n_neighbors=1)\n",
    "# Fit the model on the training data.\n",
    "classifier=knn.fit(train[x_columns], train[y_column])\n",
    "# Make point predictions on the test set using the fit model.\n",
    "predictions = knn.predict(test[x_columns])\n",
    "\n",
    "y_pred = classifier.fit(train[x_columns], train[y_column]).predict(test[x_columns])\n",
    "for i in range(0,len(y_pred)):\n",
    "    y_pred[i]=math.floor(y_pred[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(test[y_column]['label'], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=['0','1'],\n",
    "                      title='Confusion matrix, without normalization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accu=(cnf_matrix[0][0]+cnf_matrix[1][1])/(cnf_matrix[0][0]+cnf_matrix[1][1]+cnf_matrix[1][0]+cnf_matrix[0][1])\n",
    "accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=['0','1'], normalize=True,\n",
    "                      title='Normalized confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test[y_column], y_pred))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_10_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC  \n",
    "svclassifier = SVC(kernel='poly',degree=200)  \n",
    "svclassifier.fit(train[x_columns], train[y_column].values.ravel())\n",
    "y_pred = svclassifier.predict(test[x_columns])  \n",
    "cnf_matrix = confusion_matrix(test[y_column]['label'], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=['0','1'],\n",
    "                      title='Confusion matrix, without normalization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=['0','1'], normalize=True,\n",
    "                      title='Normalized confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test[y_column], y_pred))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
